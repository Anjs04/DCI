---
title: "Digital Capacities Index"
author: |
  | Liam Magee^1^, Delphine Bellerose^1^, Anjali Sharma^1^, Emma Kearney^1^, Louise Crabtree^1^, Philippa Collin^1^, Justine Humphry^1^, Paul James^1^, Tanya Notley^1^, Amanda Third^1^, Samantha Yorke^2^
  | 1. Western Sydney University
  | 2. Google Australia
date: "23 May 2016"
bibliography: DCI.bib
output:
  html_document:
    toc: true
    toc_depth: 4
    number_sections: true
    theme: united
    highlight: tango
  word_document:
    toc: true
    toc_depth: 4
---


<!--

Journal: Information Communication and Society
URL: http://www.tandfonline.com/toc/rics20/current
Instructions for Authors: http://www.tandfonline.com/action/authorSubmission?journalCode=rics20&page=instructions#.V0JfRZN96uU
Word count (exclusive): 8,000

-->


```{r setup, include=FALSE, echo=FALSE}
library(captioner)
library(pryr)

knitr::opts_knit$set(root.dir="..")
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE)
setwd("..")


source("R/main-with-init.R", FALSE)
PRINTING <- FALSE

# Set to false for non-HTML (e.g. word, pdf) outputs
PLOTLY <- FALSE
rmd_output <- tryCatch({rmarkdown::metadata$output},
                         error = function(e) {NULL})
if (class(rmd_output) == "list") {
  rmd_output <- names(unlist(rmd_output)[1])
}
if (length(grep('html_document',rmd_output)) > 0) {
# if (rmd_output == 'html_document') {
  PLOTLY <- TRUE
}
PLOTLY <- FALSE


# Set up figure numbering
fig_nums <- captioner(prefix = "Figure")
cf <- partial(fig_nums, display = "cite")
fig_nums("age.freq", "Age Frequency")
fig_nums("gender.freq", "Gender Frequency")
fig_nums("gender.and.age.freq", "Age & Gender Frequency")
fig_nums("gender.and.age.freq.abs", "Australia's Age & Gender Frequency (ABS 2014)")
fig_nums("location.freq", "Location Frequency")

# Competencies
fig_nums("freq.74", "Frequency of online activity")
fig_nums("freq.431", "Perceived ease of conducting online activity")
fig_nums("freq.74.2", getLabel(2, vars.competencies.online.activities.74))
fig_nums("freq.74.3", getLabel(3, vars.competencies.online.activities.74))
fig_nums("freq.74.6", getLabel(6, vars.competencies.online.activities.74))
fig_nums("freq.74.2", getLabel(2, vars.competencies.online.activities.74))
fig_nums("freq.431.13", getLabel(13, vars.competencies.431))
fig_nums("freq.431.14", getLabel(14, vars.competencies.431))
fig_nums("freq.431.19", getLabel(19, vars.competencies.431))

# Interests
fig_nums("freq.437", "General Interests")
fig_nums("freq.341", "Interest in seeking difference")
fig_nums("freq.352", "Interest in fitness and health improvement")
fig_nums("freq.353", "Health Impacts")
fig_nums("freq.430", "Interest in keeping in touch")
fig_nums("freq.437.1", getLabel(1, vars.interests.general.437))
fig_nums("freq.437.9", getLabel(9, vars.interests.general.437))
fig_nums("freq.352.4", getLabel(4, vars.interests.fitness.352))


# Resilience
fig_nums("freq.434", "Frequency of harmful events")
fig_nums("freq.435", "Responses to statements about online harms")
fig_nums("freq.428", "Willingness to engage with others")
fig_nums("freq.434.4", getLabel(4, vars.resilience.harm.events.434))
fig_nums("freq.434.10", getLabel(10, vars.resilience.harm.events.434))
fig_nums("freq.435.6", getLabel(6, vars.resilience.harms.agreement.435))
fig_nums("freq.435.7", getLabel(7, vars.resilience.harms.agreement.435))

# Connectedness
fig_nums("freq.343", "Maintaining connections")
fig_nums("freq.287", "Importance of online life in maintaining relationships")
fig_nums("freq.429", "Attitudes towards Technology")
fig_nums("freq.287.1", getLabel(1, vars.connectedness.maintenance.287))
fig_nums("freq.343.4", getLabel(4, vars.connectedness.events.343))
fig_nums("freq.429.2", getLabel(2, vars.connectedness.tech.attitudes.429))


# Multivariate analysis
fig_nums("pca.variable.scree", "PCA by Variable - Variances")
fig_nums("pca.variable", "PCA by Variable - First 2 Components")
fig_nums("pca.questions.scree", "PCA by Question - Variances")
fig_nums("pca.variable", "PCA by Question - First 2 Components")
fig_nums("corrections.exploratory.totals", "Exploratory Correlations - By Question")



# Aggregated
fig_nums("agg.results", "Aggregated Results by Critical Issue")

```



# Digital Capacities Index

## Introduction

Much has been made of the transition, in 2008, of more than half the world's population to urban settlements. Far more dramatic, in terms of time and acceleration, has been the rate to which more than half the world's population have become immersed in some form of digital life. This rate has through the extraordinary rise of low cost smart phones and cheap WiFi in Asia, Africa and Latin America in the new millennium. In the decade 2005-2015, International Telecommunications Union estimates that while global mobile subscriptions grew by more than 300%, in Asia and Africa these rates were considerably higher - 448% and 785% respectively ^[http://www.itu.int/en/ITU-D/Statistics/Pages/stat/default.aspx - ref properly]. In March 2016, Ericsson reports global mobile subscriptions stand at 7.4 billion, equivalent to one for each person on the planet ^[http://www.ericsson.com/mobility-report/mobile-subscriptions ; http://www.worldometers.info/world-population/ - ref properly]. Nearly half of these, 3.2 billion, are so-called 'smartphone' subscriptions, and provide their owners with some level of access to digital content and data ^[http://www.ericsson.com/mobility-report/mobile-subscriptions]. More people still access the Internet through household or shared devices, fixed line subscriptions, or communal terminals in libraries and Internet cafes.

This rate of digitisation can be considered a second and largely invisible wave of globalisation. A thematic cornerstone of much sociological inquiry in the 1980s and 1990s, the era of globalisation and its various discontents has more recently been thought to have subsided against the giddying reemergence of neo-nationalist, economic protectionist and securitisation discourses ^[Paul to rephrase and reference]. The proliferation of digital devices and their associated carrying capacity, well testified to in recent infrastructural studies ^[ref. e.g. Rossiter, Nielsen, Notley, Lisa Parks, Nicole Starosielski, many others], does not of course imply the erasure of frictions, bumps or discontinuities that Friedman ^[cite The World is Flat], Fukuyama ^[cite The End of History] and other global enthusiasts once predicted. Yet it is not without its universalising effects. Young people in slums and informal settlements in Bangladesh are likely to communicate with the same social networking apps - _WhatsApp_, _Facebook Messenger_ - and play the same games - _Candy Crush_ or _Clash of Clans_ - as their peers in traditional centres of technological innovation, in San Francisco, London or Tokyo. In the technology industries, increasingly indissociable from other professional fields, patterns of outsourcing, consultation and collaboration build upon these collective and formative digital capacities and dispositions.

This epochal shift in communicative and informational access has been matched by an interest in assessing different facets of what is unquestionably now a globalised digital society. Since the 2000s, the measurement of digital life has developed markedly. Studies of digital connectivity [cite], access [cite], inclusion [cite], use [cite], competencies [cite], skills [cite], engagement [cite], and risk and resilience [cite] illustrate the growing complexity of patterns of digital behaviour among diverse communities, countries and regions. At the same time, amid the plethora of studies that focus on measurement of highly particular dimensions, such complexity risks obscuring broader patterns of digital life. This risk becomes acute as the forms of use of digital technologies have themselves become more pervasive and diverse. Use of devices, platforms, apps and methods of interaction expand and, periodically, contract around new products, services and standards, in rhythm with the regularised and syncopated release cycles of major vendors. Home, work and in-transit digital technologies - from mobile devices to virtual reality sets, CCTV surveillance cameras, in-flight entertainment systems, public sensors, 'smart' fitness devices and home automation systems - increasingly blur categories of explicit 'use' and 'non-uses'. As Bratton ^[cite _The Stack_] has argued, we are all 'users' now.

How then might a general empirical social analysis of the digital proceed? We argue here the preoccupation with specifically measurable qualities of digital infrastructural availability and individual interactions need to regrouped and reframed within a more comprehensive theoretical rubric. The rubric we suggest is oriented around the key concept of 'capacities', selected because of its ability to connote qualities both of technical objects, and their human makers, users and critics. Capacities capture something of the wide and open conntations of human capabilities, developed by Amartya Sen and Martha Nussbaum [cite]. At the same time, capacities also reference the technical quantities inherent in the digital world. Bandwidth, hard drives, memory and telecommunication networks, for instance, are frequently referenced and measured in terms of capacity. The related term 'capability', with its obvious associations to Sen and Nussbaum's work, translates less adequately. It acquires more specific meaning in relation to digital equipment, and even then not universally: while complex networks have capabilities, raw qualities such as bandwidth instead express at best a *single* capability. As we discuss further in *Methodology* below, this feature of translatability is an important for devices which seek to measure a varied, multidimensional and diverse set of sociotechnical variables. *Capacities* is the term which best seems to meet this demand. The close semantic and etymological proximity of 'capacity' to 'capability' does at the same time allow for a point of concordance to broader societal measures such as the _Human Development Index_, informed by Sen's *Capabilities Approach*.


## Digital Capacities: Fluid Ubiquity

The growing prevalence of digital capacities movivates our efforts to develop a general method for measuring them. Our account is, however, complicated by its goal of generality. Both the rate of technological change, and varied or differential pace of that change, mean that methodological instrumentation of theories are subject to considerable revision across space and time. At least some of our collective digital capacities alternate at the rate of hardware developments and software releases - that is, at the rate of days, weeks or months, rather than across years or decades. This contrasts with many other forms of individual or social capacities, such as the abilities to learn languages, to improve health outcomes, or to participate in political life, which vary in line with the slower pace of education diffusion, policy reform and economic development.

Similarly, the rates of digital capacity occur across complex social vectors. The expansion of programming skills - a highly developed digital capacity - through coding clinics, hackathons, interpretive scripting environments and broader social pressures to 'learn to code' represent a salient and highly instructive example. Since definitions of 'programming' vary from full-time professionals to occasional 'hackers' or 'script junkies', worldwide estimates of programmers are difficult to estimate with precision. However, some indication of gross numbers can be obtained from user metrics on popular code repositories such as GitHub [GitHub], and technical Q&A fora, such as [Stack Overflow](http://stackoverflow.com/). As of April 2014, *GitHub* reports [14 million users](https://github.com/about/press), while _Stack Overflow_ reports 4.5 million registered ['programmers'](http://stackoverflow.com/). Both are likely underestimates; many programmers do not use these sites, or access them anonymously. Despite the imprecision, these numbers represent order-of-magnitude increases over approximate estimates in the 2000s (approximately 5 million) and 1990s (under 1 million). Yet the diffusion of programming skills also follow broad trajectories of geography, education, availability of digital infrastructure: entry to the programming profession corresponds strongly to availability of tertiary education, affordable hardware, software and the Internet, and clusters of investment in technological innovation. Programmers also are sharply skewed demographically and geographically: male gendered, middle class, and urban residents ^[Need citation, and possible exapnsion here]. Yet even this characteristic has locational variation: as Poster notes in a comparative study of gender in American and Indian IT firms, 'the masculine “cultures of engineering” often cited in the US literature are weaker in my _Indian_ cases' [-@poster2013global]

A brief analysis of _GitHub_ users highlights the fact that digital capacities are not only spread spatially; this spatial distribution is also mutating rapidly. In 2010, @takhteyev2010investigating noted the top ten countries responsible for GitHub contributions included, in order: USA, UK, Germany, Canada, Brazil, Japan, France, Australia, Russia and Sweden. An estimate conducted on the last available month of public data of GitHub users locations, December 2014, showed the top ten countries now included China, India and the Netherlands, at the expense of Brazil, Russia and Sweden (which nevertheless show growth in absolute numbers). This contrasts with assumptions that open source contributors are overwhelmingly from developed economies ^[For example, a comment on the popular programming site _The Server Side_ from 2011 impatiently asked of an analysis of open source contributions: 'The results are not too surprising in that the majority are Western European or of that descent. But where are the Indian and Chinese contributors?' (Who contributes to Open Source Software?)[http://www.theserverside.com/news/thread.tss?thread_id=61806]].

Responding to the prevalence of digital infrastructure, technology education and lower costs of devices and access, these figures index the global growth and relative geographic change of digital capacity. Numerous other trends, both endogenous and exogenous to the tech industry, also impact how capacity is configured. In-built product obsolescence, switches from desktop to mobile apps, ease of accessing social media apps and networks, increases in automation and improvements in design mean certain capacities are more readily acquired, while others become forgotten or obscured.

Our definition and analysis of digital capacities foregrounds two implications of this conceptual volatility. The first implication is that any specific measureable dimension of capacity is likely to have limited 'shelf-life', both over time and across regions. This implies the need for intermediary categories of analysis to mediate between these measures and any generalised definition of capacity itself. It further suggests that while application of direct measures may not be replicable, both these intermediary levels and the very process of selecting those measures may have greater prospect for reuse across different spatiotemporal frames.

The second implication draws upon the exogenous social factors that impact upon the development of digital capacities. Policy change, community orientations, geographic proximity to centres of technology, and economic investment, particularly in infrastructure and innovation, act as spurs to the production of new capacities. It is now a truism, bourn out in recent STS qualitative analyses of households, communities and workplaces, that technology skills not develop in isolation of their social context ^[cite counter-determinist references]. Yet this relational dimension is underplayed in recent quantitative studies of skills and competencies in particular. In our own survey instrument, we seek to draw out the importance of various aspects of this relationality.

We elaborate upon both of these implications in our account of digital capacities below. We then discuss a study that operationalises that account, as part of a larger research project, through a survey of 2,000 Australian persons. We present in some detail our procedure for arriving at a set of four capacity themes, or what we term "critical issues", and associate variables or indicators. We then present the results of the survey, highlighting significant findings by demographic variables and relationships. We conclude with observations on what these results say about digital capacities of Australians in 2016, and on the methodological prospects for adapting the instrument to measure capacities in other times and places.


<!--

These results were broadly confirmed by more extensive analysis conducted in October 2014 by data analyst Nikita S. Nikitinsky on a [blog post in June 2015](http://nlpx.net/archives/172).

Relevant links:

https://www.igvita.com/slides/2012/bigquery-github-strata.pdf
http://www.itworld.com/article/2704843/cloud-computing/where-in-the-world-are-github-users-.html
https://github.com/rstats-db/bigrquery
https://www.githubarchive.org/

-->



## Towards an Approach for Defining Digital Capacity

Acknowledging the dynamic nature of digital capacities, we argue defining digital capacity is a necessarily fluid task. We have sought to develop an approach towards definition that withstands the temporariness of specific measures and indicators. That approach draws from the substantive literature on indicators developed in recent community indictor and social sustainability studies [e.g. @fraser2006bottom, @holden2013sustainability, @james2014urban]. In spite of the distinct difference in domain, this literature seeks to address many of the concerns we raise in our _Introduction_ above. First, it recognises that meanings of sustainability are highly fluid and contested across geographical and temporal boundaries. Significant issues for one community or social group may be minor for another, and with the passing of time, these issues may become more or less relevant even within the same community setting. As much as there are strong demands for standardisation and comparability in sustainability measurement, indicators must also evolve in line with the issues that matter [@magee2012issues]. Second, and in keeping with the fluid definitions of sustainability, this literature has argued that the procedures for selecting, weighting and applying indicators ought to include diverse community and expert stakeholders - they must, in other words, support "bottom-up" as much as "top-down" processes of deliberation [@fraser2006bottom]. Third, the choice of measures should be open to frequent iteration and revision; indicators that fail to communicate to communities must be revised for those that do.

In the very different context of digital capacity, these affordances still hold considerable weight, and we argue some degree of context sensitivity is equally important to measurement in this field. Of the numerous methods for indicator development, we adopted 'Circles of Sustainability' [@james2014urban] on the basis of some of the authors' familiarity with the approach in urban fieldwork. Used by the United Nations Global Compact Cities Programme, the World Association of Major Metropolises, World Vision, and a number of local governments to support their engagement in cities, the approach treats social life as made up of four key domains of economy, ecology, politics and culture [@james2014urban]. It also proposes a sequential, iterative and consultative process for selecting and refining measures -- one which accords well with our own understanding of digital capacities as a volatile object of measurement.

The approach further suggests two lower order constructs, _issues_ and _indicators_, be developed through two related consultative sessions during a design phase of measurement tools. In urban community settings, the purpose of the first session, termed an "Issue Selection" workshop, is to solicit, consult and examine the key areas of concern - and related objectives to be pursued - for the community of interest. The second session, termed an "Indicator Ratification" workshop, selects and decides upon a series of specific indicators to measure progress towards those objectives. Between and after those two events, the project team collates, drafts and finalises the indicators. Both issues and indicators can be developed organically, through a combination of further community consultation, reference to existing literature and empirical validation.

The end product of this process is one or more measurement instruments. These can be both qualitative and quantitative; administered to people, in the case of subjective or person-centric measures, or applied to objects, in the case of objective or environment-centric measures; and developed through secondary as much as primary sources, in the case of existing official, academic or publicly available data. Results from these measurements chart a series that indicates variation and progress towards objectives over time [@james2014urban].

In outlining our application of this approach in our 'Methods' section below, we make several adaptations that reflect the theoretical distinctions between sustainability and digital capacities, along with the specific conditions of our study. In particular we adapt and extend recent literature on measures of digital competencies, safety, inclusion and engagement, as we discuss further below. We identify and align relevant indicators against each of the four domains, to produce a series of economic, ecological, political and cultural indicators that at the same time correspond, where possible, to prior studies of relevant capacities.

Given our unit of analysis - families across the continent of Australia - was broad and dispersed, we also did not include community representatives in our issues and indicator workshops. Instead we conducted a series of household visits and interviews with a diverse group of eight families. Results of these studies informed both our own workshops and the subsequent survey design and pilotting. Since our view that sensitivity to technological, cultural and geographic contexts are critical to any measurement of digital capacitiy, in addition to the direct findings of our study, part of our concluding observations also reflect upon these adaptations, and particularly upon the feasibility of a reusable and repeatable _process_ - rather than _instrument_ - for the ongoing measurement of digital capacity.



## Measuring the Digital Capacity of Australian Households ^[Note: not 'families' at this time, as I think this implies more analysis that we have space for in this article.]


### Selecting Issues

In line with other studies of digital measurement, our central device for measuring digital capacities is a survey administered to a representative sample of Australian households. We employed an online panel provider to recruit participants. The panel provider was asked to ensure the sample was weighted by age, gender and location, where the latter was represented by Australian postcode. We also requested a boosted sample of young people aged 12-17, so we could undertake analysis of how digital capacities are developing among Australian youth. That analysis, along with detailed study of capacities by other demographic variables, is beyond the scope of the present work.

Data collection took place in February 2016. Prior to this, we conducted a series of activities in line with the recommendations of the _Circles_ approach. First we conducted a general scan of literature relating to digital capacities and a broad range of cognitively associated terms commonly attached to the _digital_: accessability, divide, inclusion / exclusion, experience, safety, competencies, literacy, "nativivty", regulatory environments, and comparative digital development. As the latter term suggests, we sought to incorporate non-social measures of digitality, such as the market and technological availability of capacities. We then conducted an initial "issues" workshop with six members of the project team ^[check this - Emma, Paul, Amanda, Pip, Liam, Delphine?] to develop key areas or "critical issues" relating to digital capacities. This produced a set of ten such issues that could be used to group more specific variables and measures. We outline each of these, with brief descriptions, in the list below:

 - Situational: demographic details about individuals, including their access to digital technology.
 - Interests: what motivates individuals to use digital technologies.
 - Competencies: what skills and abilities individuals possess for using digital technologies.
 - Resilience: what risks and harms individuals experience when using digital technologies, and how they manage these.
 - Social Connectedness: how individuals interact with others - both online and offline - to develop and use their capacities.
 - Engagement: how individuals engage both with digital technologies, and with other - economic, political, cultural or environmental - issues through those technologies.
 - Inclusion: how well individuals and social groups are able to access and participate in forms of digital activity.
 - Policy Environment: the state of legal frameworks supporting access, skill development and other forms of digital participation.
 - Infrastructure: the level and quality of development of digital technology (including the cost, availability and speed of broadband and Wifi connectivity, and the availability of routers, modems, cabling, devices and software)
 - Consequence: the impacts of using digital technology, including generation of e-waste and pollution, costs of technology change, and increased surveillance and invasion of privacy. ^[Note, to Emma particularly: might be better to distil to the four we use, and expand upon them. If so, could borrow summarised forms of the language you use in the qual article on resilience and connectedness.]

Collectively these issues emcompassed, in our view, a wide range of what we mean by "digital capacities" in Australia in 2016. They cover a range of key dimensions: positive as well as negative aspects of technology use; individual and social characteristic; and both human and non-human, or technical, types of capacities. However this effort at comprehensiveness proved too large for instrumentation into a single survey that could be administered in an online environment. Certain issues - particularly _Policy Environment_ and _Infrastructure_ - were also not amenable to measurement through a survey, due to varying levels of awareness among a sample of broad population.

To refine the original list of issues, and to help identify particular measures might be relevant in the current Australian context, we drew upon the findings drawn from our interviews with eight families. We reduced this original set to a shorter set of five issues: _Situational_, _Interests_, _Competencies_, _Resilience_ and _Social Connectedness_, of which _Situational_ refers to the demographic and largely non-subjective attributes of our sample. These interviews highlighted the strong interdependence of capacities within households. Family members shared devices, helped eachother with connectivity and other technical issues, and spent considerable time - contrary to some arguments about the isolating effects of technology - in communal living areas engaging with their devices. This suggested that what we term 'connectedness', which extends to neighbourly, communitarian and online social interactions, might play a similarly vital role in the development of digital dispositions in our survey sample. Further, our preliminary review suggested that this relational and supportive capacity has been comparatively neglected in existing measurement literature on capacities and related terms. This reliance upon others in physical or digital proximity therefore warranted particular attention in our own study.

For other issues, the process of selection was more straightforward. _Situational_ characteristics allowed for analysis of capacities by demographic and financial wellbeing. _Interests_ and _Competencies_ were motivated by our desire to understand why, and how well, individuals interact with digital technologies. Our interest in _Resilience_ reflected a topical interest in both the risks individuals - particularly young people - are exposed to through their online activities, as well as their capacities to cope with and manage these risks.


### Selecting Indicators

With the exception of _Connectedness_, indicators of our selected critical issues are well developed in the literature. As a further step in preparing the survey, we conducted a more detailed search of other quantitative studies that developed and applied measures of these particular capacities.  In particular we drew from 'Kids Online' [@livingstone2010risks], Helsper's [-@helsper2012corresponding] 'Corresponding fields model', a study by Humphry [-@humphry2014importance] of mobile use among homeless populations, and indicators compiled by the [Young and Well CRC](http://www.youngandwellcrc.org.au/) [-@crc2013standardmeasures], a large Australian-based research initiative that has explored how digital technologies can better support young people's wellbeing. Other indicators were developed by the *Digital Capacities Index* team. These indicators were compiled into a database of approximately 430 indicators ^[Note: should link to an online open access version. Would need clearance from various authors].

This database formed the basic input to a follow-up all day workshop to select indicators. A number of indicators were flagged as duplicates; those remaining were scored on a simple three-point scale for relevance to our five nominated issues and the Australian context. Some measures of _Engagement_, _Inclusion_ and _Consequences_, taken from other surveys, were integrated into _Connectedness_. Time constraints on the length of the survey - approximately 25 minutes for completion, including consent forms and demographic variables - constrained the number that could be included. The workshop nominated approximately 60 'candidate' indicators to carry forward to pilotting; these were eventually limited to a subset of 26 questions; 11 relating to demographic and other situational characteristics, and the remaining 15 spread across the other 4 issues (see _Appendex 1_ ^[consider putting the survey as an Appendix, or online.]). All but two of these questions contained varying number of statements, scaled according to (a) frequency of various online behaviour, (b) levels of agreement with statements about digital capacities, (c) perceived importance of online activities and (d) ease of use of digital technologies. The remaining two, relating to support given to or received from others, included 'yes/no' responses. A total of 158 statements were included in the survey, broken into the four critical issues as follows:

- **Competencies** (`r length(vars.competencies)` indicators).
- **Interests** (`r length(vars.interest)` indicators).
- **Resilience** (`r length(vars.resilience)` indicators).
- **Social Connectedness** (`r length(vars.connectedness)` indicators).


### Survey Administration and Analysis

In the latter months of 2015, the survey was pilotted with approximately 20 test respondents. We also consulted a number of international digital scholars and practitioners. Feedback from the pilot was incorporated into the final draft administered to the sample in early 2016. The survey included a total of `r format(sampleSize(), big.mark   = ",")` participants. We requested the survey provider provide a panel in terms of age groups, gender and geographic regions. As the panel provider recruited participants online, our sample is expected to be skewed towards Australian citizens and families with comparatively high digital capacities. This caveat is signficant to the interpretation of our results below ^[This is a basic overview, and perhaps enough. Delphine to provide more information if necessary].

In terms of analysing our results, one limitation of our consultative and syncretic approach to indicator develoment is that theorisation of relationships between both higher-order issues (_Interests_, _Connectedness_, and so on) can need to be reconstructed _post facto_. We use two approaches to dealing with this risk. First, we draw upon several of the relationships developed in the studies that have been sources of our indicators, and supplement these with our own additional hypotheses. Second, we employ exploratory factor analysis and principal component analysis. We employ the latter analysis to determine whether specific statements adequately align to our higher order groupings of indicators and critical issues ^[Discussion with Delphine on "top-down" theories, discussion on "bottom-up" theories].


## Surveying Digital Capacities

We present our survey findings in three sections. In the first section, we present our descriptive data. In the second section, we show both correlations obtained from direct tests of relationships, and the results of our factor and principal component analyses. In the third section, we discuss how these results are used to compose a simple index that summarises responses to the individual indicators, both under the four issue categories and for the instrument as a whole.


### Descriptive Findings

<!-- Insert histograms and choropleths here -->


#### Demographic Distributions

Our articipants' ages ranged from `r min(data$age)` to `r max(data$age)`, with a median value of `r median(data$age)`.

*`r cf("age.freq")`* provides more detailed age demographics:

```{r ageFreq, echo=FALSE}

(gg <- chartWrap(ageChart(data)))

```

**`r fig_nums("age.freq")`**

These show participants' ages correspond approximately to Australia's adult demographic. `r top4AgesAsPercentage()` of participants were aged 35-54.


Participant gender is fairly evenly distributed across the sample. The survey included `r format(length(which(data$gender == "Female")), big.mark   = ",")` (`r format(100 * length(which(data$gender == "Female")) / length(data$gender), digits = 2)`%) women; `r format(length(which(data$gender == "Male")), big.mark   = ",")` (`r format(100 * length(which(data$gender == "Male")) / length(data$gender), digits = 2)`%) men; and `r format(length(which(data$gender == "Other")), big.mark   = ",")` (`r format(100 * length(which(data$gender == "Other")) / length(data$gender), digits = 2)`%) identifying as 'Other'.

`r cf("gender.freq")` illustrates the gender distrubtion of the sample:

```{r genderFreq, echo=FALSE}

(gg <- chartWrap(genderChart(data)))

```

**`r fig_nums("gender.freq")`**


We also combined age and gender frequences, as shown in *`r cf("gender.and.age.freq")`*:

```{r genderAndAgeFreq, echo=FALSE}

(gg <- chartWrap(genderAndAgeChart(data)))

```

**`r fig_nums("gender.and.age.freq")`**

These figures approximate to Australia's adult age distribution, as reported by the ABS in 2014 in **`r cf("gender.and.age.freq.abs")`** below, though with a considerably higher skew towards younger women and older men.


![Population Structure, Age and sex - Australia - 1994 and 2014](http://www.abs.gov.au/ausstats/abs@.nsf/0/1cd2b1952afc5e7aca257298000f2e76/Body/0.2A9C!OpenElement&FieldElemFormat=gif)

**`r fig_nums("gender.and.age.freq.abs")`**


Survey distribution by state follows Australia's demographic distribution more closely. The split of participants between urban and regional/rural is as follows:

```{r locationFreq, fig.height = 2, echo=FALSE}

(gg <- chartWrap(locationChart(data)))

```
**`r fig_nums("location.freq")`**

The percentage of reported urban residents here is `r formatC(100 * length(data[data$location == "Urban", "location"]) / length(data[,"location"]))` - considerably less than [World Bank figures of 89%](http://data.worldbank.org/indicator/SP.URB.TOTL.IN.ZS).


#### Competencies

In relation to competencies, participants were asked to respond to two questions:

 - Frequency of online activity
 - Perceived ease of conducting online activity

*Frequency of online activity* measures frequency of 15 different activities, ranging from highly common activities such as sending email through to less common activities (in 2016), such as writing blogs.

`r cf("freq.74")` below shows the relative frequencies of each activity. Using the Internet generally (for work, study, and for personal use), sending email and social networking are the most common activities. Streaming music, playing games with others, sharing media, and writing blogs or diaries are comparatively uncommon activities.


```{r graphSubQuestion74, fig.width = 8, fig.height = 9.5, echo=FALSE}

(gg <- chartWrap(graphSubQuestionFrequencies(
  vars.competencies.online.activities.74,
  "Frequency",
  frequencyLabels,
  "online-activities-74",
  -6.0,
  yawcrcPaletteFivePoints
  )))

```

**`r fig_nums("freq.74")`**


Respondents were also asked to rate the ease or difficulty of 27 online activities. Overall respondents report a high level of competency across all activities with bookmarking a website and connecting to a wifi network scoring the highest. Understanding the language that others use online and creating a blog were reported as more difficult activities. Despite the high level of competence reported by respondents in each of the 27 activities there were a small percentage of respondents who reported each of these activities as difficult or very difficult. Analysing the results according to age ranges provides a more illustrative breakdown of the results.

```{r graphSubQuestion431, fig.width = 8, fig.height = 15.5, echo=FALSE}

(gg <- chartWrap(graphSubQuestionFrequencies(
    vars.competencies.431,
    "Ease",
    easeLabels,
    "competencies-ease-of-tasks-431",
    -7.5,
    yawcrcPaletteFivePoints)))

```

**`r fig_nums("freq.431")`**



#### Interests

We asked five questions on the critical issue of *Interests*:

 - Frequency of online activity
 - Interest in seeking difference
 - Interest in fitness
 - Interest in health improvement
 - Interest in keeping in touch

*Frequency of online activity* measures frequency of 11 different activities related to information seeking, ranging from highly common activities, such as looking for information about general interests on platforms such as Wikipedia, through to more specific activities (in 2016), such as national government services.

*`r cf("freq.437")`* below shows the relative frequencies of each activity. Looking for information about a topic of general interest where answers were provided by Wikipedia, Quora or other informational sites, and searching for prices are the most common activities. Looking for information about concerts and events, and political or societal issues are comparatively uncommon activities.



```{r graphSubQuestion437, fig.width = 8, fig.height = 7.5, echo=FALSE}

(gg <- chartWrap(graphSubQuestionFrequencies(vars.interests.general.437, "Frequency", frequencyMonthLabels, "interests-general-437", -8.0)))

```

**`r fig_nums("freq.437")`**



The question about *Interest in seeking difference*  measured frequency of 7 different online activities whose main purpose is to determine to what extent online information seeking helps people to find others who share their interests and to learn about or understand social and cultural difference.

*`r cf("freq.341")`* below shows the relative frequencies of each activity. Finding people of a similar age who share my interests is the most frequent and most commonly reported activity, followed by learning new things about people with mental illnesses or physical disabilities and learning new things about other ethnic groups. Learning things about participant's own ethnic group and feeling more connected to spiritual or religious beliefs are less common. This suggests that for Australians, online information seeking is more directed towards questions of interest, gender and health, rather than ethnicity and religion.


```{r graphSubQuestion341, fig.width = 8, fig.height = 6.0, echo=FALSE}

(gg <- chartWrap(graphSubQuestionFrequencies(vars.interests.difference.seeking.341,
  "Agreement",
  agreementLabels,
  "interests-difference-seeking-341",
  -7.5,
  yawcrcPaletteFivePoints)))

```

**`r fig_nums("freq.341")`**


The question on *Interest in fitness and health improvement* measured frequency of 10 different online activities whose main purpose is to determine to what extent online technologies assist people to manage their health and fitness.

*`r cf("freq.352")`* below shows the relative frequencies of each activity. Looking up information or asking others about a training program is the most frequent and commonly reported activity, followed by looking up information or asking advice on a medical condition. The least common activities reported are participating in an online health or fitness community and filling out questionnaires about fitness. There are not large differences reported between any of the activities, and less than 40% of participants reported engaging in any of the activities on more than a monthly basis.


```{r graphSubQuestion352, fig.width = 8, fig.height = 7, echo=FALSE}

(gg <- chartWrap(graphSubQuestionFrequencies(vars.interests.fitness.352, "Frequency", frequencyMonthLabels, "interests-fitness-352", -5.0)))

```

**`r fig_nums("freq.352")`**

We asked a series of subsidiary statements about use of digital capacities to improve health. More participants agreed than disagreed (32% to 17%) with the statement they made better decisions as a result of online advice. In terms of outcomes, responses were more evenly split: 25% agreed their health had improved, while 20% disagreed.

```{r graphSubQuestion353, fig.width = 8, fig.height = 3.5, echo=FALSE}

(gg <- chartWrap(graphSubQuestionFrequencies(
  vars.interests.health.improvement.353,
  "Agreement", agreementLabels, "interests-health-improvement-353", -7.5,
  yawcrcPaletteFivePoints)))

```

**`r fig_nums("freq.353")`**


The survey asked respondents to rate the importance of their motivations for using the internet for maintaining their general interests, along with their connections with others. Respondents were asked to rate 14 statements which ranged between extremely important and not important at all. All the statements were rated with a degree of  importance in over 50% of all responses. "Communicating with friends and family" was rated the highest, with over 90% of respondents rating this on the scale of importance. Opening up new worlds and fueling my imagination also scored highly.  Less common in the scale was providing continuity of connection in a changing world.  This suggests that the reasons that motivate people to use the internet are contingent upon their connections with others and their sense of self.


```{r graphSubQuestion430, fig.width = 8, fig.height = 7.5, echo=FALSE}

(gg <- chartWrap(graphSubQuestionFrequencies(vars.interests.keeping.in.touch.430, "Importance", importanceLabels, "keeping-in-touch-430", -5.0)))

```

**`r fig_nums("freq.430")`**



#### Resilience

Our survey asked participants to respond to three questions about potential risks and harms of online activity, and how they prepare themselves for dealing with them:

 - Experience of potential risks and harms of online activity in the last 12 months
 - Level of agreement with statements about potential risks and harms
 - Level of agreement with statements about engaging with others online


*Frequency of harmful events* measures frequency of 11 risks of online activity. These include getting a virus on one's device or seeing upsetting content online, or actions taken as a protection measure against those risks, such as reporting an issue online, deleting data or blocking further contacts from an individual.

**_`r cf("freq.434")`_ below shows the relative frequencies of experiencing a risk, or taking a specific action in response to a risk, in the last 12 months.
**

On average, more than half of respondents (51%) reported having never experienced these risks or potentially harmful events. The event that was most commonly experienced was 'Seeing or experiencing something on the internet that had bothered them in some way' with 55% of respondents experiencing this at least once in the last 12 months, and 14% reporting experiencing this on a weekly basis or more often.

Half of respondents reported taking protective measures, such as blocking further contacts from an individual or deleting data in response to security and privacy concerns, at least once in the last 12 months.

Although respondents reported experiencing potentially harmful events online, the frequency of such events remains generally low. The most frequently reported action in response to online risks is to use extra security measures to protect privacy.

```{r graphSubQuestion434, fig.width = 8, fig.height = 8,  echo=FALSE}

(gg <- chartWrap(graphSubQuestionFrequencies(vars.resilience.harm.events.434, "Frequency", frequencyMonthLabels, "resilience-harm-events-434", -8.5)))

```

**`r fig_nums("freq.434")`**


*`r cf("freq.435")`* below shows the level of agreement with a number of statements relating to online harms.

Despite reporting having experienced some potentially harmful events in the last 12 months, the level of agreement with statements about online harms of a more general nature show an overall positive attitude towards those risks. The majority of respondents agree or strongly agree that the opportunities of online activities outweigh its risks and that some level of online risk is inevitable but also provides an important learning opportunity.

Online security and safety remains a pressing concern for just over a third of respondents but there appears to be both an increased level of acceptance and the development of coping mechanisms to better manage the risks.


```{r graphSubQuestion435, fig.width = 8, fig.height = 5.5, echo=FALSE}

(gg <- chartWrap(graphSubQuestionFrequencies(
  vars.resilience.harms.agreement.435,
  "Agreement", agreementLabels, "resilience-harms-agreement-435", -6.5,
  yawcrcPaletteFivePoints)))

```

**`r fig_nums("freq.435")`**


Thinking about how they feel when they engage with others online, respondents were asked to what extent they agree with several statements relating to their willingness to engage with others.

For each of these statements, a large proportion of respondents neither agree nor disagree. People tend to disagree that it is easier to be oneself online than face to face or that they talk about private things online that they do not share face to face. Similar proportions agree or disagree that going online makes them feel better when they are going through a difficult time.

```{r graphSubQuestion428, fig.width = 8, fig.height = 5.5, echo=FALSE}

(gg <- chartWrap(graphSubQuestionFrequencies(vars.resilience.engage.with.others.428,
  "Agreement", agreementLabels, "resilience-engage-with-others-428", -7.0,
  yawcrcPaletteFivePoints)))

```

**`r fig_nums("freq.428")`**




#### Social Connectedness

Our survey asked participants to respond to questions about social connectedness and the role technology plays in their interactions with other people. Key topics include:

  * Frequency of online activity to maintain connections
  * Importance of online life to maintaining relationships
  * Level of agreement with statements about broader issues concerning technology


The first question measures frequency of 8 different online activities whose main purpose, or direct consequence, is to interact with others or to maintain connections.

*`r cf("freq.343")`* below shows the relative frequencies of each activity. Reading updates from friends or family via email or social media is the most frequent and most commonly reported activity, followed by making comments on those updates. Making new friends, meeting people or looking at websites that help meet new people are less common. This suggests that online activity is primarily used to strengthen connection with offline networks rather than as a distinct circle of connections.

```{r graphSubQuestion343, fig.width = 8, fig.height = 6, echo=FALSE}

(gg <- chartWrap(graphSubQuestionFrequencies(vars.connectedness.events.343, "Frequency", frequencyMonthLabels, "connectedness-events-343")))

```

**`r fig_nums("freq.343")`**



When asked how important online life is in maintaining relationships with various groups within a broader social network, friends and family were the two groups with the highest level of importance. Online is also considered important in maintaining relationships with other networks of interest and work or school peers, but comparatively not as important to the maintenance of relationships with neighbours.

```{r graphSubQuestion287, fig.width = 8, fig.height = 5, echo=FALSE}

(gg <- chartWrap(graphSubQuestionFrequencies(vars.connectedness.maintenance.287, "Importance", importanceLabels, "maintaining-connections-287", -4.8)))

```

**`r fig_nums("freq.287")`**



The survey also asked respondents to what extent they agree or disagree with a number of statements with regards to attitudes towards broader issues concerning technology.

Similar to our findings on the more general statements about online risks and harms, the attitudes of respondents towards technology is especially positive with over 60% reporting being optimistic about the future of technology. Nearly three quarters (74%) agree or strongly agree that technology is part of everyday life. Nearly half (49%) believe that technology can not only make participants more effective members of their community or nation, but can also foster social inclusion.

The positive attitude is nevertheless counterbalanced with concerns about the use of online information by governments or companies, the impact on the environment or the growing divide between technology experts and the rest of society.

```{r graphSubQuestion429, fig.width = 8, fig.height = 6.5, echo=FALSE}

(gg <- chartWrap(graphSubQuestionFrequencies(vars.connectedness.tech.attitudes.429, "Agreement", agreementLabels, "connectedness-tech-attitudes-429", -7.0,
  yawcrcPaletteFivePoints)))

```

**`r fig_nums("freq.429")`**






### Exploring Responses: A Principal Component Analysis

```{r pca-setup, echo=FALSE}
d.pca <- prcomp(data.scaled[,vars.index.no.quals], center = TRUE, scale. = TRUE)
d.sum.variances <- length(d.pca$sdev)
d.pca$relative.variance <- d.pca$sdev**2 / d.sum.variances * 100
comp1 <- d.pca$rotation[,1]
comp2 <- d.pca$rotation[,2]
comp3 <- d.pca$rotation[,3]
comp4 <- d.pca$rotation[,4]
comp1.stack <- stack(comp1[order(-stack(comp1)$values ** 2)])
comp2.stack <- stack(comp2[order(-stack(comp2)$values ** 2)])
comp3.stack <- stack(comp3[order(-stack(comp3)$values ** 2)])
comp4.stack <- stack(comp4[order(-stack(comp4)$values ** 2)])
top20 <- comp4.stack[1:20,]
top20$q <- as.character( sapply( gsub('_.*', '', top20$ind), questionCategory ) )
top20$ci <- as.character( sapply( gsub('_.*', '', top20$ind), questionIssue ) )
top20$ci.q <- paste(top20$ci, ": ", top20$q, sep = "")
top20.melted <- melt(table(top20$ci.q))
top20.melted <- top20.melted[order(-top20.melted$value),]
top20.melted
top20.percentage <- sum(top20$values ** 2) * 100
top20.percentage
comp1.sd <- sd(comp1 ** 2) * 100
comp2.sd <- sd(comp2 ** 2) * 100
comp3.sd <- sd(comp3 ** 2) * 100
comp4.sd <- sd(comp4 ** 2) * 100

dt.pca <- prcomp(data.scaled[,vars.totals.no.quals], center = TRUE, scale. = TRUE)
dt.sum.variances <- length(dt.pca$sdev)
dt.pca$relative.variance <- dt.pca$sdev**2 / dt.sum.variances * 100

```

We conducted two principal component analyses of the survey data. The first is applied to
each of the individual statements included in the survey, with the exception of
qualitative variables that measured whether respondents had offered or received technical support from others around them. The second is applied at the question level, again excluding the qualitative variables. Both analyses were conducted to explore, firstly, whether each set of variables and questions could be more effectively summarised, and to test, secondly, whether respondent variances were consistent with our groupings by critical issue.

Both analyses were conducted in _R_, using the stats' package _prcomp()_ function with _center_ and _scale_ parameters set to 'TRUE'. For both analyses, we show and discuss two graphs: the relative variances between components, and the distribution of respondents by the first two components.


#### PCA by Variable

*`r cf("pca.variable.scree")`* shows the relative contribution of each component to variances in the data, generated by the analysis of 133 variables. The steep asymptote illustrates that a relatively small number of components contribute to these variances. The first component makes up `r d.pca$relative.variance[1]` per cent of the variance; the first seven components make `r d.pca$relative.variance[1:7]` per cent; and the first twenty components make up `r d.pca$relative.variance[1:20]` per cent ^[Need a note on collinearity?].

```{r pca-variables-scree, fig.width = 8, fig.height = 8, echo=FALSE}

generateScreeForPCA(d.pca)

```
**`r fig_nums("pca.variable.scree")`**


*`r cf("pca.variable.scree")`* shows the first two components plotted, and for illustrative purposes, colored by reponses to the gender question. This confirms the first component, while only accounting for little more than a quarter of the overall variance, is significantly more influential than the second component. Differences in gender is limited, though the elliptical banding shows males score higher against the first component, while females and those who responded 'Other' score higher against the second component.


```{r pca-variables, fig.width = 8, fig.height = 8, echo=FALSE}

generateGraphForPCA(d.pca)

```
**`r fig_nums("pca.variable")`**


We then examined the top 20 rotation values for the first component. Their frequencies, shown in _Table 1_ below, show that the critical issue of 'interests' represent 17, or 85%, of the most significant variables contributing to this component. This suggests that interests relate strongly to this first component, and account for a larger amount of the overall variance of the survey data. However the combined variances of the top 20 variable comprise only 22% of the component, and the contribution of all 133 variables to this component is relatively homogenous. The standard deviation of the variances, also expressed in percentile terms, is only 0.25%.

```{r pca-variables-top, fig.width = 8, fig.height = 8, echo=FALSE}

top20.melted

```

We also plotted an exploratory correlation matrix, as shown in *`r cf("corrections.exploratory")`* below. This depicts the directions and intensities of all individual variables correlated with eachother, in the order questions associated with these variables were asked in the survey. Again, qualitative variables related to support are removed, as are situational variables.

The visualisation matrix dhows that none of the 133 variables correlate negatively, which would be shown in red. Instead correlations vary from uncorrelated or weakly correlated (white, faint purple) through to strongly correlated (purple, dark blue). Of particular significance are the larger squares that follow the diagonal - these show that statements belonging to the same question elicit highly comparable responses. The same pattern holds more weakly for statements belonging to the same critical issue.

```{r correlation-exploratory, fig.width = 8, fig.height = 8, echo=FALSE}
generateCorrelationsExploratory()
```

**`r fig_nums("corrections.exploratory")`**

Several implications follow from this analysis. First, the first component accounts for considerably greater variation than other components. Yet, despite the apparent influence of the 'Interests' critical issue, the contribution of individual variables to this component is quite uniform. This implies that the survey is not readily reducible to a smaller set of variables; all of those included play a role in the overall variance. We found similar patterns of minimal rotational differences in the variances of components 2, 3 and 4.

Second, the exploratory correlation matrix illustrates that strong correlations are all in a positive direction. In no cases would participants exhibit weak capacities in one area and strong capacities in another. At worst, different capacities may not be correlated at all.

Third, individual statements correlate strongly with other statements under the same question, and to a lesser degree, with other statements under the same issue. This implies the survey design appropriately groups statements and questions under issues, and lends some weak support to the conceptual coherence of the issues themselves. Together with the lack of evident decomposition of variables to clearly identifiable components, this also lends support to the conclusion that the four digital capacities are both positively interrelated in complex ways, and that their indicators are easily reducible to latent alternatives.


#### PCA by Question



```{r pca-questions-scree, fig.width = 8, fig.height = 8, echo=FALSE}

generateScreeForPCA(dt.pca)

```

**`r fig_nums("pca.questions.scree")`**


```{r pca-questions, fig.width = 8, fig.height = 8, echo=FALSE}

generateGraphForPCA(dt.pca)

```

**`r fig_nums("pca.questions")`**











<!--

#### Demographics

_To what extent does education correlates with competencies and interests?_

 - Skills (Q431) by education level (Q436)

```{r correlation-skills-educations, fig.width = 8, fig.height = 6, echo=FALSE}
generateCorrelation("total.431", "Q436", "skills-education")
```



 - Interest (Q437) by education level (Q436)


_Relationship between occupation and aspects of digital capacities_

 - Reasons for using internet (Q430) by occupation (Q8)
 - Interests: what type of info look for online (Q437) by occupation (Q8)
 - Connectedness: Providing help (Q277) or seeking help (Q280) by occupation (Q8)

_Relationship between financial pressure and aspects of digital capacities_

 - Financial pressure generally (Q45)
 - Financial pressure from digital access (Q425)
 - Low income (Q9_214)


_By competencies and interests: uses of the internet (Q74), what you look for (Q437), reasons for use (430)_

_By resilience: attitude twds harm/risk (Q435)_

_By connectedness: relationships (Q287), frequency of connecting (Q343)_

_Minority groups_

 - Interests: what type of info look for online (Q437) by minority grps (Q9)
 - Seeking help (Q280) by minority grp (Q9)
 - Minority groups (Q9) by current location (Q427)
 - Are gender differences more pronounced in some grps?

_Families_

 - Does gender have an effect for different types of families?
 - 'families': analyse by size of household (Q24), sole parents (Q9_215), households with children (CH1) (look at 5-17 especially?)
 - Household with children + CALD(Q9_212)/Indigenous(Q9_218)


#### Competencies / Interests

_To what extent various levels of competencies (use + skills) translate into knowledge sharing?
Higher level of competencies into providing help and/or lower level into seeking help_

 - Helping others (Q277) by skills (Q431), use (Q74)
 - Seeking help (Q280) by skills (Q431), use (Q74)
 - At statement level, social media:
    - 74_7 use social media
    - 431_23 update status
    - 431_24 upload onto social media
    - 277_113 help set up social media account
    - 280_125 sought help to set up social media account
 - At statement level, safety
    - 431_32 find info on how to use internet safely
    - 431_38 restrict access to adult content
    - 431_42 anonymise
    - 277_120 help on how to stay safe
    - 280_132 been shown how to stay safe

_Can different uses of the internet (Q74), different interests (Q437) or reasons for use (Q430) help identifying profiles or types of engagement?
How do different uses/interest (types of engagement) correlate to different types, or level, of resilience and connectedness?
_

#### Resilience/safety

_Does higher level of use lead to increased exposure to risk? Does lower level of skills mean increased exposure to risk?_

 - Correlation between use (Q74) and resilience (Q435)
 - Correlation between use (Q74) and risks (Q434)
 - Between skills (Q431) and resilience (Q435)
 - Find information on using the internet safely (431_32) by attitude twds harm/risk (Q435)

_How does risk exposure impact on attitude towards risks/harms?_

 - exposure to potential harm (Q434_91, 92, 93) by attitude twds harm/risk (Q435)


#### Connectedness

Exploring technology as an enabler of social connectedness.

Can digital technology facilitate settling into new location and/or establish social/community network?
 - current location (Q427). Combine 179+180+181 into <6 months to get a sample of 218
   - made new friends/met new people online (Q343_149)
   - info on gvt serv (Q437_51)
 - 280_126 help to find info and resources

_How/to what extent does tech support social connectedness of minority grps?_

 - learn new things about my ethnic grp (341_57)
   - by CALD (Q9_212), Indigenous (Q9_218), Refugees (Q9_213), Homeless? (Q9_220)
 - 	Find people of similar age/interests online (Q341_55)
   - by gender (check sig)
   - by age (correlates, but 35+ do not disagree more rather N/A increases: check with 35+ with higher competency/use?)
   - by minority groups

_focus on social media as a very specific online activity to explore connectedness and resilience_

 - Use of soc media (74_7) in relation to connectedness, and to resilience (428, 434_92, 277_122)
 - Interacting using text or IM (431_25) in relation to connectedness

#### Notes

Best to not use hypotheses at high level (4 critical issues): very likely to find that more competencies correlates with more interested, more connected, better support, more resilient...
But at a lower level: are there diff types of resilience, do types of competencies lead to better/more supportive networks?
within those 4 areas: need to classify types of skills, types of support networks etc.

In a previous conversation, we had discussed the different uses of the internet: from a more informational/technical use to a more emotional/social involvement, with the overarching question/hypothesis: does the emotional/social use lead to increased connectedness, and in turn to increased resilience?

Those two ‘types’, informational and social, can be applied across the 4 critical issues and many of the survey questions. Within each questions, below are the variables that I think best outline one or the other.

-->




### Composing an Index of Digital Capacities

<!-- Insert indexes here -->

#### Aggregates by Critical Issue

To gain an overall picture of our results, we generated a series of stacked graphs in *`r fig_nums("agg.results")`*. These aggregate responses to each critical issue (*Competencies*, *Interests*, *Resilience* and *Competencies*), and the combined total.

These results are indicative only, and have several evident limitations we discuss further below. The procedure to generate scores for each of the issues is as follows:

1. Interpret each question as having either a *positive* or *negative* influence of the score of the critical issue. For example, "Frequency of harmful events" has a *negative influence* on the issue of Resilience (and indeed, on overall "Digital Capacities").
2. Determine the *direction* of the scale coding. For example, in all of our "Agreement" questions, "Strongly Agree" was coded **1**.
3. For each question, calculate a question score based on both its interpretation and direction, by adding responses to individual items.
4. For each respondent, add each of their question scores to produce a respondent critical issue score. This value is converted to a percentile, where '100%' would indicate maximum responses to each item for each question in that critical issue.
5. A combined score is taken by averaging the four critical issue scores.

`r cf("agg.results")` then displays the relative frequencies of these scores, similar to the preceding individual question graphs. Because values are continuous (anywhere on a scale between 0 and 100 per cent), the graphs show a spectrum from blue (indicating a low score) to bright yellow (indicating a high score).

The *Resilience* score is calculated in the same way as the other issue scores, with the exception that only the first two items under *Question 428*, "Willingness to engage with others", are included in the scoring procedure. We have intepreted these items ("When I am going through a difficult time, I go online less often"; "When I am going through a difficult time, going online makes me feel better") as having some influence (the first negative, the second positive) on *Resilience*.


*`r cf("agg.results")`* shows that results for *Compentencies* and *Connectedness* are evenly distributed, with respondents' scores spread across the 100-point scale. These are also similar to the spread of *Combined* scores. *Resilience* scores tend high, with most respondents reporting little exposure to harms, and familiarity with methods for responding to those harms. On the other hand, *Interest* scores tend low. This may be explained by our limiting interests to areas of social difference, fitness, health and family, which will not effectively poll the range or extent of participants' interests.

```{r indexChart, echo=FALSE}

(gg <- chartWrap(generateIndexChart()))

```

This procedure was designed to communicate a sense of capacities to a broad constituency, and as such has several limitations. First, the procedure treats each of the scales as numerically regular, as ratio rather than as ordinal scales. For example, on the *Agreement* scale it assumes *Strongly agree* warrants 1 more score point than *Agree*, which in turn warrants 1 more point than *Neither Agree nor Disagree* ^[This could be corrected by weighting different items. Not done yet.] Second, the procedure assumes all questions and individual items have equal influence on the critical issue they have been aligned to. A refinement would incorporate a weighting on key indicators; a step we have not undertaken in this case. [Issue of defintion].


## The Digital Capacities of Australian Households

Our work to define digital capacities, and administer a survey of these capacities across Australian households has produced a rich set of data and observations. Each of individual questions and statements shows a reasonable diversity of capacities across the Australian population. As a baseline study, there are no prior data sets to compare with, though our focus on deriving indicators from other sources leaves open the prospect for partial comparison of particular capacities - particularly competencies and resilience - with prior work both in Australia and internationally. The exploratory PCA and correlation tests and aggregated results our definition and measurement of distinct issues are relatively robust, and could be replicated at least in further Australian studies. Though Australia is generally regarded as an advanced national consumer of digital goods and services, the variances demonstrate the capacities of its population are moderately diverse. Further work with both this and other datasets could explore in more detail how these capacities are distinguished between age groups, gender, location and other demographics. Among specific groups and locations, this survey data could also be supplemented with qualitative data to understand in more detail how and why distinctions in capacities emerge.

Our inclusion of connectedness, and the strong correlations between our indicators of this and other issues highlights the fact that employment of digital capacities in 2016 is no longer intrinsically related to the specific 'technical' aptitudes of individuals. Such capacities now adhere to social as much as individual units of analysis. This lends support both to the Bourdieusian-inspired discussion of fields in @helsper2012corresponding, and our own highly relational approach derived from work in the community indicator and urban sustainability disciplines [@james2014urban].




## Appendix 1 - _Digital Capacities Index_ Survey

^[Running into word length issues by including the full survey, especially on top of the large number of graphs. Consider posting the survey online and linking to it.]

## References
